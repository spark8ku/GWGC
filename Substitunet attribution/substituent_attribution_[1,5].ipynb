{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f217575d-7b0f-40ff-9ffa-64b627e7f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from rdkit import Chem\n",
    "\n",
    "import xgboost as xgboost\n",
    "import catboost as catboost\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f398c83c-0196-4666-b6fb-f590892a387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuma_branch_sol_emi = pd.read_csv(\"../data/cuma_branch in D4C DB/cuma_branch_sol_emi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38611020-12cf-4fec-a125-07671e6da4ab",
   "metadata": {},
   "source": [
    "# combination of substituents(position1, position5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352b621-aa52-4e3a-9278-987c7370269d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connsidering position1 and position5\n",
    "locom_int_list=[[1,5]]\n",
    "\n",
    "# 20 common subgstituents smiles\n",
    "common_20_subgroup_df = pd.read_csv('../data/common_20_subgroups.csv')\n",
    "common_20_subgroup=np.array(common_20_subgroup_df['sub smiles'])\n",
    "\n",
    "# Union of all substituents at each position in DB and 20 common substituents\"\n",
    "a=list(cuma_branch_sol_emi['1'].drop_duplicates())\n",
    "a= list(set(a) | set(common_20_subgroup))\n",
    "\n",
    "e=list(cuma_branch_sol_emi['5'].drop_duplicates())\n",
    "e= list(set(e) | set(common_20_subgroup))\n",
    "\n",
    "subgroup_6_smiles=[]\n",
    "sub_list=[a, np.array([]), np.array([]),np.array([]),e,np.array([])]\n",
    "\n",
    "for li in sub_list:\n",
    "    subgroup_6_smiles.append(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df5736a-10dc-42a2-a25c-80e2b2f90277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all combination of substituent smiles\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "input_smiles_final = []\n",
    "current_batch = []\n",
    "\n",
    "\n",
    "for locom in locom_int_list:\n",
    "    subsmiles_in_comb = [subgroup_6_smiles[locations-1] for locations in locom]\n",
    "    for combo in product(*subsmiles_in_comb):\n",
    "        branch_stand = ['loc1','loc2','loc3','loc4','loc5','loc6']\n",
    "        for idx, loc in enumerate(locom):\n",
    "            branch_stand[loc-1] = combo[idx]\n",
    "        current_batch.append(branch_stand)     \n",
    "        if len(current_batch) >= chunk_size:\n",
    "            input_smiles_final.append(np.vstack(current_batch))\n",
    "            current_batch =[]\n",
    "\n",
    "\n",
    "if current_batch:\n",
    "    input_smiles_final.append(np.vstack(current_batch))\n",
    "    \n",
    "input_smiles_final_array = np.vstack(input_smiles_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b543f54-3580-40fd-9965-4433efd6de1d",
   "metadata": {},
   "source": [
    "# Using XGBoost model for emission wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6d8f0-ffcd-483f-a3bf-719d7c9a05ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functions.conv_input_Gauss_function import one_touch_representation_Gauss\n",
    "\n",
    "cuma_branch_sol_emi = pd.read_csv(\"../data/cuma_branch in D4C DB/cuma_branch_sol_emi.csv\")\n",
    "X_emi= one_touch_representation_Gauss(cuma_branch_sol_emi,10,  10*( 0.6645613384222082/10), True)\n",
    "\n",
    "Y_emi = np.array(cuma_branch_sol_emi['Emi']).flatten()\n",
    "scaler = StandardScaler()\n",
    "scaled_Y_emi = scaler.fit_transform(Y_emi.reshape(-1,1)).flatten()\n",
    "\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_estimators = 89, learning_rate= 0.12170962342182974, subsample =0.6765177031554993, max_depth = 9, random_state=42)\n",
    "xgb.fit(X_emi, scaled_Y_emi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e778b-f878-4434-ad4c-6dc4930fb751",
   "metadata": {},
   "source": [
    "# augment & predict (in DMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147220f5-0189-415e-9f85-864b26e0059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentes_X_conv_input_in_sol(solvent, sub_smiles_combo, conv_range, sigma_ratio):\n",
    "\n",
    "    \n",
    "    chunk_size = 10000\n",
    "    current_batch = []\n",
    "    augmented_x_conv=[]\n",
    "    \n",
    "    \n",
    "    #solvent_conv\n",
    "    sol_feature, sol_adj = _make_matrix([solvent], conv_range, sigma_ratio, True) \n",
    "    sol_matirx = np.dot(sol_adj[0], sol_feature[0])\n",
    "    sol_conv_1D = np.dot(np.ones(sol_adj[0].shape[0]),sol_matirx)\n",
    "    \n",
    "    \n",
    "    cuma_mol = Chem.MolFromSmiles('O=C1C=CC2=CC=CC=C2O1')\n",
    "    core_sub_site_order = [2,3,5,6,7,8]\n",
    "    \n",
    "    #만든 조합 중에 폐기 되는 애들 인덱스 수집\n",
    "    deleted_combi=[]\n",
    "    for n in tqdm(range(len(sub_smiles_combo))):\n",
    "        \n",
    "        # get_sub_atom_index\n",
    "        core = [Chem.MolFromSmarts('[#8]=[#6:1]1:[#6:2](-[#101:3]):[#6:4](-[#102:5]):[#6:6]2:[#6:7](-[#103:8]):[#6:9](-[#104:10]):[#6:11](-[#105:12]):[#6:13](-[#106:14]):[#6:15]:2:[#8:16]:1')]\n",
    "    \n",
    "        where_sub_is=[]\n",
    "        what_sub_is=[]\n",
    "        skip_to_next_n = False \n",
    "        \n",
    "        for sub_loc, sub_smiles in enumerate(sub_smiles_combo[n]):\n",
    "            if sub_smiles[0]=='*':\n",
    "\n",
    "                chain = Chem.MolFromSmarts(sub_smiles.replace('*','',1))\n",
    "                if chain is None:\n",
    "                    print(f\"Skipping invalid SMILES: {sub_smiles}, moving to next n\")\n",
    "                    deleted_combi.append(n)\n",
    "                    skip_to_next_n = True \n",
    "                    break \n",
    "                \n",
    "                core = Chem.ReplaceSubstructs(core[0], Chem.MolFromSmarts(f'[#{sub_loc+101}]'),chain)\n",
    "                if core is None or not isinstance(core, tuple):\n",
    "                    print(f\"Invalid core after ReplaceSubstructs for sub_loc {sub_loc}, sub_smiles {sub_smiles}\")\n",
    "                    deleted_combi.append(n)\n",
    "                    skip_to_next_n = True \n",
    "                    break \n",
    "                where_sub_is.append(sub_loc)\n",
    "                what_sub_is.append(sub_smiles)\n",
    "                \n",
    "            else : \n",
    "                core = Chem.ReplaceSubstructs(core[0], Chem.MolFromSmarts(f'[#{sub_loc+101}]'),Chem.MolFromSmarts('[#1]'))\n",
    "                continue\n",
    "    \n",
    "        if skip_to_next_n:\n",
    "            continue  \n",
    "\n",
    "        try:\n",
    "            whole_mol = Chem.MolFromSmiles(Chem.MolToSmiles(core[0]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in MolToSmiles : smiles which is augmented: {e}\")\n",
    "            deleted_combi.append(n)\n",
    "            continue\n",
    "        \n",
    "        core_idx = whole_mol.GetSubstructMatches(cuma_mol)[0]\n",
    "    \n",
    "        sub_atomidx_list = []\n",
    "        for m in range(len(where_sub_is)):\n",
    "            sub_idx_candidates = whole_mol.GetSubstructMatches(Chem.MolFromSmiles(what_sub_is[m].replace('*','C',1)))\n",
    "            sub_idx_candidates = np.array(sub_idx_candidates)\n",
    "    \n",
    "            core_site = np.isin(sub_idx_candidates, core_idx[core_sub_site_order[where_sub_is[m]]])\n",
    "            scam_check = np.isin(sub_idx_candidates, core_idx)\n",
    "            pick_correct_one = np.where((core_site.any(axis=1))&(np.sum(scam_check, axis=1)==1))[0][0]\n",
    "            \n",
    "            sub_idx = list(sub_idx_candidates[pick_correct_one])\n",
    "            sub_idx.remove( core_idx[core_sub_site_order[where_sub_is[m]]] )\n",
    "            sub_atomidx_list.append(sub_idx)\n",
    "    \n",
    "        \n",
    "        # making Gaussian weighted graph convolution matirx\n",
    "        new_feature, new_adj = _make_matrix([Chem.MolToSmiles(core[0])], conv_range, sigma_ratio, True)\n",
    "        feature_matirx = np.dot(new_adj[0], new_feature[0])\n",
    "    \n",
    "    \n",
    "        #making subgruop_modular_GGC_input\n",
    "        all_subs_conv_1D = np.zeros(6*45)\n",
    "        for x in range(len(sub_atomidx_list)):\n",
    "            sub_conv = feature_matirx[sub_atomidx_list[x],:]\n",
    "            sub_conv_1D = np.dot(np.ones(len(sub_atomidx_list[x])), sub_conv)\n",
    "            all_subs_conv_1D[where_sub_is[x]*45:(where_sub_is[x]+1)*45] = sub_conv_1D\n",
    "        if sub_atomidx_list:   \n",
    "            del_sub_atoms = np.hstack(sub_atomidx_list)\n",
    "        else:\n",
    "            del_sub_atoms = np.array([])\n",
    "\n",
    "        if del_sub_atoms.size > 0 :\n",
    "            core_conv = np.delete(feature_matirx, del_sub_atoms, axis=0)\n",
    "        else:\n",
    "            core_conv = feature_matirx.copy()\n",
    "\n",
    "        core_conv_1D = np.dot(np.ones(feature_matirx.shape[0]-len(del_sub_atoms)), core_conv)\n",
    "    \n",
    "        conv_branch = np.hstack((sol_conv_1D, core_conv_1D, all_subs_conv_1D)) \n",
    "        \n",
    "        current_batch.append(conv_branch)\n",
    "        if len(current_batch) >= chunk_size:\n",
    "                augmented_x_conv.append(np.vstack(current_batch))\n",
    "                current_batch =[]\n",
    "    \n",
    "    \n",
    "\n",
    "    if current_batch:\n",
    "        augmented_x_conv.append(np.vstack(current_batch))\n",
    "        \n",
    "    augmented_x_conv_final = np.vstack(augmented_x_conv)\n",
    "    return augmented_x_conv_final, deleted_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17895043-947b-4585-b993-42599b41ee59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functions.conv_input_Gauss_function import _make_matrix, predict_chunky\n",
    "import gc\n",
    "\n",
    "for sol, solname in zip(['CN(C)C=O'], ['DMF']):\n",
    "    print(f'solvent : {solname} ({sol})')\n",
    "    augmented_x_conv_final, deleted_combi = augmentes_X_conv_input_in_sol(sol, input_smiles_final_array, 10, 0.6645613384222082)\n",
    "\n",
    "    all_predict = predict_chunky(augmented_x_conv_final, 10000, xgb)\n",
    "    all_predict = scaler.inverse_transform(all_predict.reshape(-1,1)).reshape(all_predict.shape[0],)\n",
    "    np.save(f'augment_predict_{solname}', all_predict)\n",
    "\n",
    "    del all_predict  \n",
    "    gc.collect()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ecb7a-8b75-4525-a57a-3e0c332e3230",
   "metadata": {},
   "source": [
    "# Attribution of 20 substituents to emission wavelength (in DMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f116038-9d7b-489d-b28e-508b68d22f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "solname = 'DMF'\n",
    "predict_on_sol = np.load(f\"augment_predict_{solname}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8efea-8ce2-4607-81de-1ddc7d11ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_smiles_final_array=np.delete(input_smiles_final_array, deleted_combi, axis=0)\n",
    "\n",
    "location_chunk = 20\n",
    "delta_basic_20=[]\n",
    "delta_basic_6loc=[]\n",
    "\n",
    "for loc in [0,4]:\n",
    "    for subidx in np.arange(20):\n",
    "        \n",
    "        predict_stand = predict_on_sol[input_smiles_final_array[:,loc] == common_20_subgroup[subidx]] # in DMF\n",
    "        print(f'loc : {loc}, index : {subidx}',len(predict_stand))\n",
    "    \n",
    "        sub_combo_observe = input_smiles_final_array[input_smiles_final_array[:,loc] == common_20_subgroup[subidx]].astype(object).copy()\n",
    "        sub_combo_observe[:,loc] = 'deleted'\n",
    "        input_compare, deletes_combi2 = augmentes_X_conv_input_in_sol('CN(C)C=O', sub_combo_observe, 10, 0.6645613384222082) \n",
    "        \n",
    "        predict_compare = predict_chunky(input_compare, 10000, xgb)\n",
    "        predict_compare = scaler.inverse_transform(predict_compare.reshape(-1,1)).reshape(predict_compare.shape[0],)\n",
    "        delta = predict_stand - predict_compare\n",
    "        delta_basic_20.append(delta)\n",
    "    \n",
    "        if len(delta_basic_20) >= location_chunk:\n",
    "            delta_basic_6loc.append(delta_basic_20)\n",
    "            delta_basic_20 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0fbda-bd17-4907-bc3d-59db85207e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_subgroup_shift_DMF = pd.DataFrame([])\n",
    "for idx,loc in enumerate([1,5]):\n",
    "    common_subgroup_shift_DMF[f'location {loc}'] = [np.mean(delta_basic_6loc[idx][n]) for n in range(20)]\n",
    "common_subgroup_shift_DMF.index=common_20_subgroup_df['sub name']\n",
    "common_subgroup_shift_DMF.index.name = 'functional group'\n",
    "print(common_subgroup_shift_DMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb079091-afd0-47e8-9755-25567ccd3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_subgroup_shift_DMF.to_csv('common_subgroup_shift_DMF_[1,5].csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269ff95-2dad-4d04-9da1-2619430fedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for idx, position in enumerate([1,5]) :\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    violin = sns.violinplot(data=delta_basic_6loc[idx])\n",
    "    plt.title(f'Attribution of functional groups (position{position})', fontsize =27)\n",
    "    plt.xlim(-1,19.5)\n",
    "    violin.set_xticks(range(20))\n",
    "    violin.set_xticklabels(list(common_20_subgroup_df['sub name']), rotation =90, fontsize =25)\n",
    "    plt.ylabel('Emission λ shift (nm)', fontsize =25)\n",
    "    plt.yticks(fontsize =22)\n",
    "    sns.lineplot(x=np.arange(-1,21), y=0, linestyle='--', color ='gray')\n",
    "   \n",
    "    plt.tight_layout() \n",
    "    fig = violin.get_figure()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksw",
   "language": "python",
   "name": "ksw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
