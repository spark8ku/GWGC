{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0293ed2-d2f2-4f20-9213-fdc37eabf3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from rdkit import Chem\n",
    "\n",
    "import xgboost as xgboost\n",
    "import catboost as catboost\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d559a506-cd9d-4d4c-a69f-035b962b6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_symbol_HNums(atom):\n",
    "    \n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "                                      ['C', 'N', 'O','S', 'H', 'F', 'Cl', 'Br', 'I','Se','Te','Si','P','B','Sn','Ge'])+\n",
    "                    one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]))\n",
    "\n",
    "\n",
    "def atom_degree(atom):\n",
    "    return np.array(one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5 ,6])).astype(int) \n",
    "\n",
    "\n",
    "def atom_Aroma(atom):\n",
    "    return np.array([atom.GetIsAromatic()]).astype(int)\n",
    "\n",
    "\n",
    "def atom_Hybrid(atom):\n",
    "    return np.array(one_of_k_encoding_unk(str(atom.GetHybridization()),['S','SP','SP2','SP3','SP3D','SP3D2'])).astype(int)\n",
    "\n",
    "\n",
    "def atom_ring(atom):\n",
    "    return np.array([atom.IsInRing()]).astype(int)\n",
    "\n",
    "\n",
    "def atom_FC(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetFormalCharge(), [-4,-3,-2,-1, 0, 1, 2, 3, 4])).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443ed4e-5d46-458a-bc45-5278d7bd1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Adj(mol, conv_range, sigma, BO):\n",
    "    A = Chem.rdmolops.GetDistanceMatrix(mol, useBO=BO)\n",
    "    A_Gauss= np.exp(-((A)**2) / (2 * sigma**2))\n",
    "    A_Gauss[A > conv_range] = 0\n",
    "    \n",
    "    return A_Gauss\n",
    "\n",
    "\n",
    "def _convertToAdj_Gauss(smiles_list, conv_range, sigma, BO):\n",
    "    adj = [Gaussian_Adj(Chem.MolFromSmiles(i), conv_range, sigma, BO) for i in smiles_list]\n",
    "\n",
    "    max_atom_nums = np.max([i_adj.shape[0] for i_adj in adj]) \n",
    "\n",
    "    adj = np.concatenate([np.pad(i_adj,((0,max_atom_nums-i_adj.shape[0]),\n",
    "                                        (0,max_atom_nums-i_adj.shape[0])),\n",
    "                                 'constant',\n",
    "                                 constant_values=0).reshape(1,\n",
    "                                                            max_atom_nums,\n",
    "                                                            max_atom_nums) for i_adj in adj],\n",
    "                         axis=0)\n",
    "\n",
    "    return adj, max_atom_nums\n",
    "    \n",
    "def _convertToAdj_sigma0(smiles_list):\n",
    "    adj = [np.eye(len(Chem.MolFromSmiles(i).GetAtoms())) for i in smiles_list]\n",
    "\n",
    "    max_atom_nums = np.max([i_adj.shape[0] for i_adj in adj]) \n",
    "\n",
    "    adj = np.concatenate([np.pad(i_adj,((0,max_atom_nums-i_adj.shape[0]),\n",
    "                                        (0,max_atom_nums-i_adj.shape[0])),\n",
    "                                 'constant',\n",
    "                                 constant_values=0).reshape(1,\n",
    "                                                            max_atom_nums,\n",
    "                                                            max_atom_nums) for i_adj in adj], \n",
    "                         axis=0)\n",
    "\n",
    "    return adj, max_atom_nums\n",
    "\n",
    "\n",
    "def _convertToFeatures(smiles_list,max_atom_nums):\n",
    "    features = [np.concatenate([np.concatenate([atom_symbol_HNums(atom),\n",
    "                                                atom_degree(atom),\n",
    "                                                atom_Aroma(atom),\n",
    "                                                atom_Hybrid(atom),\n",
    "                                                atom_ring(atom),\n",
    "                                                atom_FC(atom)],\n",
    "                                               axis=0).reshape(1,-1)\\\n",
    "                                for atom in Chem.MolFromSmiles(i).GetAtoms()],axis=0)\\\n",
    "                if i !='gas' else np.zeros([2,45]) for i in smiles_list]\n",
    "\n",
    "    features = np.concatenate([np.pad(i_features,\n",
    "                                      ((0,max_atom_nums-i_features.shape[0]),\n",
    "                                       (0,0)),\n",
    "                                      'constant',\n",
    "                                      constant_values=0).reshape(1,\n",
    "                                                                 max_atom_nums,\n",
    "                                                                 -1)\\\n",
    "                               for i_features in features],axis=0)\n",
    "\n",
    "    return features\n",
    "\n",
    "def _make_matrix(smiles_list, conv_range, sigma, BO):\n",
    "    adj, max_atom_nums = _convertToAdj_Gauss(smiles_list, conv_range, sigma, BO)\n",
    "    features = _convertToFeatures(smiles_list, max_atom_nums)\n",
    "    \n",
    "    return features, adj\n",
    "\n",
    "def _make_matrix_sigma0(smiles_list):\n",
    "    adj, max_atom_nums = _convertToAdj_sigma0(smiles_list)\n",
    "    features = _convertToFeatures(smiles_list, max_atom_nums)\n",
    "    \n",
    "    return features, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb1b0d-cd48-4a18-a3c4-1b3807dafefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_atomidx_df(cuma_data):\n",
    "    core_order = [2,3,5,6,7,8]\n",
    "    \n",
    "    # cuma_data <-- cuma_branch_sol_abs 또는 cuma_branch_sol_emi\n",
    "    cuma_mol = Chem.MolFromSmiles('O=C1C=CC2=CC=CC=C2O1')\n",
    "    mol_list =[]\n",
    "    for i in range(len(cuma_data)):\n",
    "        smiles = cuma_data['Chromophore_smiles'].iloc[i]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        core_idx = mol.GetSubstructMatches(cuma_mol)[0]\n",
    "        \n",
    "\n",
    "        cuma_subgroups = cuma_data[cuma_data.columns[20:27]].drop(['glob_6'], axis=1).iloc[i]\n",
    "        sub_list =[]\n",
    "        loc = 0\n",
    "        for ishere in ~cuma_subgroups.isna():\n",
    "            if ishere ==True:\n",
    "\n",
    "                sub_idx_candidates = mol.GetSubstructMatches(Chem.MolFromSmiles(cuma_subgroups.iloc[loc].replace('*','C',1)))\n",
    "                sub_idx_candidates = np.array(sub_idx_candidates)\n",
    "             \n",
    "\n",
    "                core_site = np.isin(sub_idx_candidates, core_idx[core_order[loc]])\n",
    "                scam_check = np.isin(sub_idx_candidates, core_idx)\n",
    "                which_one = np.where((core_site.any(axis=1))&(np.sum(scam_check, axis=1)==1))[0][0]\n",
    "\n",
    "                \n",
    "                sub_idx = list(sub_idx_candidates[which_one])\n",
    "                sub_idx.remove(core_idx[core_order[loc]] ) \n",
    "                sub_list.append(sub_idx)\n",
    "                loc+=1\n",
    "            else : \n",
    "                sub_list.append(None)\n",
    "                loc+=1\n",
    "                    \n",
    "\n",
    "        mol_list.append(sub_list)\n",
    "    sub_idx_df = pd.DataFrame(mol_list)\n",
    "    sub_idx_df.columns=['1','2','3','4','5','6']\n",
    "    return sub_idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63ee49-45cb-4dbc-a5b6-810e51a43c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_branched_x_conv(x_conv, sub_idx_df):\n",
    "    x_conv_branch = []\n",
    "    for i in range(len(x_conv)):\n",
    "        all_subs_conv_1D = np.zeros(6*45)\n",
    "        del_sub_atoms = []\n",
    "        for loc in range(6):\n",
    "            if ~sub_idx_df.iloc[i].isna().iloc[loc] == True:\n",
    "                sub_atoms = sub_idx_df.iloc[i].iloc[loc]\n",
    "                del_sub_atoms.append(sub_atoms)\n",
    "            else : \n",
    "                continue\n",
    "            sub_conv = x_conv[i][sub_atoms,:]\n",
    "            sub_conv_1D = np.dot(np.ones(len(sub_atoms)), sub_conv)\n",
    "            all_subs_conv_1D[loc*45:(loc+1)*45] = sub_conv_1D\n",
    "            \n",
    "        del_sub_atoms = np.hstack(del_sub_atoms)\n",
    "        core_conv = np.delete(x_conv[i], del_sub_atoms, axis=0)\n",
    "        core_conv_1D = np.dot(np.ones(x_conv[i].shape[0]-len(del_sub_atoms)), core_conv)\n",
    "\n",
    "        conv_branch = np.hstack((core_conv_1D, all_subs_conv_1D))\n",
    "        x_conv_branch.append(conv_branch)\n",
    "\n",
    "    x_conv_branch = np.vstack(x_conv_branch)\n",
    "    \n",
    "    return x_conv_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16e002-f22f-4bb0-a9fd-df2561bbc310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_touch_representation_Gauss(data, conv_range, sigma, BO):\n",
    "\n",
    "    # data : cuma_branch_sol_abs or cuma_branch_sol_emi\n",
    "\n",
    "    if 2 * sigma**2 <= np.finfo(np.float64).eps :\n",
    "        new_feature, new_adj = _make_matrix_sigma0(data['Chromophore_smiles'])\n",
    "    else :\n",
    "        new_feature, new_adj = _make_matrix(data['Chromophore_smiles'], conv_range, sigma, BO)\n",
    "\n",
    "\n",
    "\n",
    "    x_conv=[]\n",
    "    for i in range(len(new_feature)):\n",
    "        conved =np.dot(new_adj[i], new_feature[i])\n",
    "        x_conv.append(conved)\n",
    "\n",
    "    each_module_atomidx = get_sub_atomidx_df(data)\n",
    "\n",
    "    X_conv_branch = make_branched_x_conv(x_conv, each_module_atomidx)\n",
    "\n",
    "    \n",
    "    # solvent\n",
    "    if 2 * sigma**2 <= np.finfo(np.float64).eps :\n",
    "        sol_feature, sol_adj = _make_matrix_sigma0(data['Solvent_smiles'] )\n",
    "    else:\n",
    "        sol_feature, sol_adj = _make_matrix(data['Solvent_smiles'], conv_range, sigma, BO)\n",
    "\n",
    "    sol_conv=[]\n",
    "    for i in range(len(sol_feature)):\n",
    "        conved =np.dot(sol_adj[i], sol_feature[i])\n",
    "        conved_1D = np.dot(np.ones(sol_adj[i].shape[0]),conved)\n",
    "        sol_conv.append(conved_1D)\n",
    "    sol_conv = np.vstack(sol_conv)\n",
    "\n",
    "    X_conv_branch_final = np.hstack(( sol_conv,X_conv_branch))\n",
    "    return X_conv_branch_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e85318-7d8a-4949-9ff4-e97c8ed91cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chunky(input, chunk_size, model):\n",
    "    \n",
    "    # 데이터 사이즈와 분할 크기 설정\n",
    "    data_size = input.shape[0]\n",
    "    \n",
    "    prediction = []\n",
    "    \n",
    "    for start in range(0, data_size, chunk_size):\n",
    "        end = min(start + chunk_size, data_size)  # 마지막 청크가 너무 클 경우를 대비\n",
    "        part = input[start:end, :]\n",
    "        predict = model.predict(part)\n",
    "        prediction.append(predict)\n",
    "    \n",
    "    \n",
    "    prediction = np.concatenate(prediction, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33e4f8-bb76-4bd2-ad85-25bf10903004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_bayesian_Gauss_sigma(data, emi_or_abs, test_ratio, log_file, BO, init_points=1000, n_iter = 500):\n",
    "    #data = cuma_branch_sol_emi or cuma_branch_sol_abs\n",
    "\n",
    "    label= np.array(data[emi_or_abs]).flatten()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(label.reshape(-1,1))\n",
    "    \n",
    "    def custom_scoring(target, pred):\n",
    "        mae= metrics.mean_absolute_error(scaler.inverse_transform(target.reshape(-1,1)), scaler.inverse_transform(pred.reshape(-1,1)))\n",
    "        return mae\n",
    "\n",
    "    count=0\n",
    "    best_mae = float('inf')\n",
    "    kfold = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "  \n",
    "    def xgb_target(c_range, sigma_ratio, a,b,c,d):\n",
    "\n",
    "        nonlocal count, best_mae\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(data, int(c_range),  int(c_range)*(sigma_ratio/10), BO)\n",
    "\n",
    "        x_train_val, x_test, y_train_val, y_test = train_test_split(input_final, label, test_size=test_ratio, shuffle=True, random_state=42) \n",
    "        scaled_y_train_val = scaler.transform(y_train_val.reshape(-1,1))\n",
    "\n",
    "        \n",
    "        xgb = xgboost.XGBRegressor(n_estimators = int(a), learning_rate=b, subsample = c, max_depth = int(d))\n",
    "        scores = cross_val_score(xgb , \n",
    "                        x_train_val , \n",
    "                        scaled_y_train_val ,\n",
    "                        cv=kfold,\n",
    "                        scoring=make_scorer(custom_scoring)\n",
    "                        )\n",
    "\n",
    "        xgb_mae = np.mean(scores)\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "        if count%10 ==0:\n",
    "            print(f'iter :{count}')\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'iter : {count}\\n')\n",
    "            \n",
    "        if xgb_mae < best_mae:\n",
    "            best_mae = xgb_mae\n",
    "            current_opt(xgb_mae, [c_range, sigma_ratio, a,b,c,d], count)\n",
    "        \n",
    "        return -xgb_mae\n",
    "\n",
    "    def current_opt(best_mae, best_params, count):\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f'iter : {count} , mae: {best_mae} param: {best_params}\\n')\n",
    "    \n",
    "    bay_op = BayesianOptimization(xgb_target, {'c_range' : (1, 13) ,'sigma_ratio' : (0, 10),'a': (10, 100), 'b' : (0, 0.2), 'c': (0.5, 1), 'd' : (5, 10)}, \n",
    "                                       random_state=0, allow_duplicate_points=True)\n",
    "    \n",
    "    result= bay_op.maximize(init_points, n_iter)\n",
    "    best = -bay_op.max['target']\n",
    "    print(\"Best MAE:\", best)\n",
    "    print(\"Best parameters:\", bay_op.max['params'])\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac69766d-d08d-4220-bcb6-22b80e0c1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_bayesian_Gauss_sigma(data, emi_or_abs, test_ratio, log_file, BO, init_points=1000, n_iter = 500):\n",
    "    #data = cuma_branch_sol_emi or cuma_branch_sol_abs\n",
    "\n",
    "    label= np.array(data[emi_or_abs]).flatten()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(label.reshape(-1,1))\n",
    "    \n",
    "    def custom_scoring(target, pred):\n",
    "        mae= metrics.mean_absolute_error(scaler.inverse_transform(target.reshape(-1,1)), scaler.inverse_transform(pred.reshape(-1,1)))\n",
    "        return mae\n",
    "\n",
    "    count=0\n",
    "    best_mae = float('inf')\n",
    "    kfold = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "  \n",
    "    def rnd_target(c_range, sigma_ratio, a,b):\n",
    "\n",
    "        nonlocal count, best_mae\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(data, int(c_range),  int(c_range)*(sigma_ratio/10), BO)\n",
    "\n",
    "        x_train_val, x_test, y_train_val, y_test = train_test_split(input_final, label, test_size=test_ratio, shuffle=True, random_state=42) \n",
    "        scaled_y_train_val = scaler.transform(y_train_val.reshape(-1,1)).flatten()\n",
    "\n",
    "        \n",
    "        rnd=ensemble.RandomForestRegressor(n_estimators = int(a), max_depth= int(b))\n",
    "        scores = cross_val_score(rnd , \n",
    "                        x_train_val , \n",
    "                        scaled_y_train_val ,\n",
    "                        cv=kfold,\n",
    "                        scoring=make_scorer(custom_scoring)\n",
    "                        )\n",
    "\n",
    "        rnd_mae = np.mean(scores)\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "        if count%10 ==0:\n",
    "            print(f'iter :{count}')\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'iter : {count}\\n')\n",
    "            \n",
    "        if rnd_mae < best_mae:\n",
    "            best_mae = rnd_mae\n",
    "            current_opt(rnd_mae, [c_range, sigma_ratio, a,b], count)\n",
    "        \n",
    "        return -rnd_mae\n",
    "\n",
    "    def current_opt(best_mae, best_params, count):\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f'iter : {count} , mae: {best_mae} param: {best_params}\\n')\n",
    "    \n",
    "    bay_op = BayesianOptimization(rnd_target, {'c_range' : (1, 13) ,'sigma_ratio' : (0, 10),'a': (10, 100), 'b' : (1, 200)}, \n",
    "                                       random_state=0, allow_duplicate_points=True)\n",
    "    \n",
    "    result= bay_op.maximize(init_points, n_iter)\n",
    "    best = -bay_op.max['target']\n",
    "    print(\"Best MAE:\", best)\n",
    "    print(\"Best parameters:\", bay_op.max['params'])\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56dbbe-1e5e-4bc5-9230-8874e08bd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_bayesian_Gauss_sigma(data, emi_or_abs, test_ratio, log_file, BO, init_points=1000, n_iter = 500):\n",
    "    #data = cuma_branch_sol_emi or cuma_branch_sol_abs\n",
    "\n",
    "    label= np.array(data[emi_or_abs]).flatten()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(label.reshape(-1,1))\n",
    "    \n",
    "    def custom_scoring(target, pred):\n",
    "        mae= metrics.mean_absolute_error(scaler.inverse_transform(target.reshape(-1,1)), scaler.inverse_transform(pred.reshape(-1,1)))\n",
    "        return mae\n",
    "\n",
    "    count=0\n",
    "    best_mae = float('inf')\n",
    "    kfold = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "  \n",
    "    def cat_target(c_range, sigma_ratio):\n",
    "\n",
    "        nonlocal count, best_mae\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(data, int(c_range),  int(c_range)*(sigma_ratio/10), BO)\n",
    "\n",
    "        x_train_val, x_test, y_train_val, y_test = train_test_split(input_final, label, test_size=test_ratio, shuffle=True, random_state=42) \n",
    "        scaled_y_train_val = scaler.transform(y_train_val.reshape(-1,1))\n",
    "\n",
    "        \n",
    "        cat = catboost.CatBoostRegressor(silent = True)\n",
    "        scores = cross_val_score(cat , \n",
    "                        x_train_val , \n",
    "                        scaled_y_train_val ,\n",
    "                        cv=kfold,\n",
    "                        scoring=make_scorer(custom_scoring)\n",
    "                        )\n",
    "\n",
    "        cat_mae = np.mean(scores)\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "        if count%10 ==0:\n",
    "            print(f'iter :{count}')\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'iter : {count}\\n')\n",
    "            \n",
    "        if cat_mae < best_mae:\n",
    "            best_mae = cat_mae\n",
    "            current_opt(cat_mae, [c_range, sigma_ratio], count)\n",
    "        \n",
    "        return -cat_mae\n",
    "\n",
    "    def current_opt(best_mae, best_params, count):\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f'iter : {count} , mae: {best_mae} param: {best_params}\\n')\n",
    "    \n",
    "    bay_op = BayesianOptimization(cat_target, {'c_range' : (1, 13) ,'sigma_ratio' : (0, 10)}, \n",
    "                                       random_state=0, allow_duplicate_points=True)\n",
    "    \n",
    "    result= bay_op.maximize(init_points, n_iter)\n",
    "    best = -bay_op.max['target']\n",
    "    print(\"Best MAE:\", best)\n",
    "    print(\"Best parameters:\", bay_op.max['params'])\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fcd1b0a-c938-4672-a1e5-cc81527063c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayesian_with_data_cv_mol_test():\n",
    "\n",
    "    def __init__(self, emi_or_abs, coumarin_data, test_ratio, model, log_file, BO, init_points = 1000, n_iter= 500):\n",
    "        self.emi_or_abs = emi_or_abs\n",
    "        self.coumarin_data = coumarin_data\n",
    "        self.test_ratio = test_ratio \n",
    "        self.label = np.array(coumarin_data[emi_or_abs]).reshape(-1,1)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(self.label)\n",
    "        self.scaled_label = self.scaler.transform(self.label)\n",
    "\n",
    "        self.model = model\n",
    "        self.log_file = log_file\n",
    "        self.BO = BO\n",
    "        self.init_points = init_points\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.count=0\n",
    "        self.best_mae = float('inf')\n",
    "\n",
    "        self.cv_set, self.test_set = self.make_test_set_split_only_by_mol(self.coumarin_data, self.test_ratio)\n",
    "        self.cv_label = np.array(self.cv_set[emi_or_abs]).flatten()\n",
    "        self.scaled_cv_label = self.scaler.transform(self.cv_label.reshape(-1,1))\n",
    "        self.test_label = np.array(self.test_set[emi_or_abs]).flatten()\n",
    "        self.scaled_test_label = self.scaler.transform(self.test_label.reshape(-1,1))\n",
    "\n",
    "        self.kfold = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "\n",
    "    def make_test_set_split_only_by_mol(self, data, test_ratio, random_state = 42):\n",
    "        mol_class = data[\"Chromophore_smiles\"].drop_duplicates()\n",
    "        mol_train = mol_class.sample(frac = (1-test_ratio), random_state = random_state)\n",
    "        mol_test = mol_class.loc[list(set(list(mol_class.index))-set(list(mol_train.index)))]\n",
    "        \n",
    "        cv_set = pd.DataFrame()\n",
    "        for mol in mol_train:\n",
    "            cv_set = pd.concat([cv_set, data[data[\"Chromophore_smiles\"] == mol]],axis=0)\n",
    "        cv_set.index = range(len(cv_set))\n",
    "\n",
    "        test_set = pd.DataFrame()\n",
    "        for mol in mol_test:\n",
    "            test_set = pd.concat([test_set, data[data[\"Chromophore_smiles\"] == mol]],axis=0)\n",
    "        test_set.index = range(len(test_set))\n",
    "    \n",
    "        return cv_set, test_set\n",
    "\n",
    "    def custom_scoring(self, target, pred):\n",
    "        mae= metrics.mean_absolute_error(self.scaler.inverse_transform(target.reshape(-1,1)), self.scaler.inverse_transform(pred.reshape(-1,1)))\n",
    "        return mae\n",
    "    \n",
    "    def try_param_xgb(self, c_range, sigma_ratio, a,b,c,d):\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(self.cv_set, int(c_range),  int(c_range)*(sigma_ratio/10), self.BO)\n",
    "        \n",
    "        xgb = xgboost.XGBRegressor(n_estimators = int(a), learning_rate=b, subsample = c, max_depth = int(d))\n",
    "        scores = cross_val_score(xgb , \n",
    "                        input_final , \n",
    "                        self.scaled_cv_label ,\n",
    "                        cv=self.kfold,\n",
    "                        scoring=make_scorer(self.custom_scoring)\n",
    "                        )\n",
    "\n",
    "        xgb_mae = np.mean(scores)\n",
    "\n",
    "        self.count += 1\n",
    "    \n",
    "        if self.count%10 ==0:\n",
    "            print(f'iter :{self.count}')\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count}\\n')\n",
    "            \n",
    "        if xgb_mae < self.best_mae:\n",
    "            self.best_mae = xgb_mae\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count} , mae: {self.best_mae} param: {[c_range, sigma_ratio, a,b,c,d]}\\n')\n",
    "            print(f'Current Best MAE : {self.best_mae} | Current Best Parameters : {[c_range, sigma_ratio, a,b,c,d]}')\n",
    "\n",
    "        return -xgb_mae\n",
    "\n",
    "    def try_param_cat(self, c_range, sigma_ratio, a, b, c):\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(self.cv_set, int(c_range),  int(c_range)*(sigma_ratio/10), self.BO)\n",
    "        \n",
    "        cat = catboost.CatBoostRegressor(silent = True, learning_rate=a, depth = int(b), l2_leaf_reg=int(c))\n",
    "        scores = cross_val_score(cat , \n",
    "                        input_final , \n",
    "                        self.scaled_cv_label ,\n",
    "                        cv=self.kfold,\n",
    "                        scoring=make_scorer(self.custom_scoring)\n",
    "                        )\n",
    "\n",
    "        cat_mae = np.mean(scores)\n",
    "\n",
    "        self.count += 1\n",
    "    \n",
    "        if self.count%10 ==0:\n",
    "            print(f'iter :{self.count}')\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count}\\n')\n",
    "            \n",
    "        if cat_mae < self.best_mae:\n",
    "            self.best_mae = cat_mae\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count} , mae: {self.best_mae} param: {[c_range, sigma_ratio, a, b, c]}\\n')\n",
    "            print(f'Current Best MAE : {self.best_mae} | Current Best Parameters : {[c_range, sigma_ratio, a, b, c]}')\n",
    "        \n",
    "        return -cat_mae\n",
    "    \n",
    "    def try_param_rnd(self, c_range, sigma_ratio, a,b):\n",
    "\n",
    "        input_final = one_touch_representation_Gauss(self.cv_set, int(c_range),  int(c_range)*(sigma_ratio/10), self.BO)\n",
    "        \n",
    "        rnd = ensemble.RandomForestRegressor( n_estimators = int(a), max_depth= int(b))\n",
    "        scores = cross_val_score(rnd , \n",
    "                        input_final , \n",
    "                        self.scaled_cv_label.flatten() ,\n",
    "                        cv=self.kfold,\n",
    "                        scoring=make_scorer(self.custom_scoring)\n",
    "                        )\n",
    "\n",
    "        rnd_mae = np.mean(scores)\n",
    "\n",
    "        self.count += 1\n",
    "    \n",
    "        if self.count%10 ==0:\n",
    "            print(f'iter :{self.count}')\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count}\\n')\n",
    "            \n",
    "        if rnd_mae < self.best_mae:\n",
    "            self.best_mae = rnd_mae\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f'iter : {self.count} , mae: {self.best_mae} param: {[c_range, sigma_ratio, a,b]}\\n')\n",
    "            print(f'Current Best MAE : {self.best_mae} | Current Best Parameters : {[c_range, sigma_ratio, a,b]}')\n",
    "        \n",
    "        return -rnd_mae\n",
    "\n",
    "    \n",
    "    def bayesinan_cv_with_custom_folds(self):\n",
    "        \n",
    "        if self.model == 'xgb':\n",
    "            bay_op = BayesianOptimization(self.try_param_xgb, {'c_range' : (1,13) ,'sigma_ratio' : (0, 10),'a': (10, 100), 'b' : (0, 0.2), 'c': (0.5, 1), 'd' : (5, 10)}, \n",
    "                                          random_state=0, allow_duplicate_points=True)\n",
    "        elif self.model == 'cat':\n",
    "            bay_op = BayesianOptimization(self.try_param_cat, {'c_range' : (1,13) ,'sigma_ratio' : (0, 10), 'a': (0, 0.2), 'b': (4,10), 'c': (1, 10)},\n",
    "                                                               random_state=0, allow_duplicate_points=True)\n",
    "        elif self.model == 'rnd':\n",
    "            bay_op = BayesianOptimization(self.try_param_rnd, {'c_range' : (1,13) ,'sigma_ratio' : (0, 10),'a': (10, 100), 'b' : (1, 200)}, \n",
    "                                          random_state=0, allow_duplicate_points=True)\n",
    "    \n",
    "        if self.model =='cat':\n",
    "            result = bay_op.maximize(500,200)\n",
    "        else:\n",
    "            result= bay_op.maximize(self.init_points, self.n_iter)\n",
    "        best = -bay_op.max['target']\n",
    "        print(\"Best MAE:\", best)\n",
    "        print(\"Best parameters:\", bay_op.max['params'])\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c841e-0370-44fd-b36b-7f68800e7ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksw",
   "language": "python",
   "name": "ksw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
